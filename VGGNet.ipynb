{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3880cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1d60c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_image_path='C:\\\\Users\\\\akasw\\\\Desktop\\\\Small_Scale_Dataset\\\\test\\\\A'\n",
    "post_image_path='C:\\\\Users\\\\akasw\\\\Desktop\\\\Small_Scale_Dataset\\\\test\\\\B'\n",
    "label_dir_path='C:\\\\Users\\\\akasw\\\\Desktop\\\\Small_Scale_Dataset\\\\test\\\\label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c565dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_image=[]\n",
    "post_image=[]\n",
    "label_image=[]\n",
    "for i in sorted(os.listdir(pre_image_path)):\n",
    "  image_path=os.path.join(pre_image_path,i)\n",
    "  img=cv2.imread(image_path)\n",
    "  pre_image.append(img)\n",
    "\n",
    "for i in sorted(os.listdir(post_image_path)):\n",
    "  image_path=os.path.join(test_post_image_path,i)\n",
    "  img=cv2.imread(image_path)\n",
    "  post_image.append(img)\n",
    "\n",
    "for i in sorted(os.listdir(label_dir_path)):\n",
    "  image_path=os.path.join(label_dir_path,i)\n",
    "  img=cv2.imread(image_path)\n",
    "  label_image.append(img)\n",
    "\n",
    "label=np.array(label_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a3f6f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1024, 1024, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_images = np.concatenate([pre_image, post_image], axis=3)\n",
    "concatenated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00e7e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_images=concatenated_images/255.0\n",
    "label=label/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ff5efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(concatenated_images, label, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85c18747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(1022, 1022, 3))\n",
    "\n",
    "# Freeze the base model's layers to prevent them from being updated during fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the input layer for the model\n",
    "input_layer = tf.keras.layers.Input(shape=(1024, 1024, 6))\n",
    "\n",
    "# Apply a convolutional layer to transform the input from 6 channels to 3 channels\n",
    "x = tf.keras.layers.Conv2D(3, 3, activation='relu')(input_layer)\n",
    "\n",
    "# Pass the transformed input through the base model\n",
    "x = base_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "flatten = Flatten()(x)\n",
    "predictions = Dense(1024 * 1024 * 3, activation='sigmoid')(flatten)\n",
    "\n",
    "# Create the fine-tuned model\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "\n",
    "# Reshape the target labels to match the expected shape\n",
    "Y_train_reshaped = np.reshape(Y_train, (Y_train.shape[0], 1024 * 1024 * 3))\n",
    "Y_test_reshaped = np.reshape(Y_test, (Y_test.shape[0], 1024 * 1024 * 3))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = BinaryCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Reduce the batch size\n",
    "batch_size = 11\n",
    "\n",
    "# Train the model with the reshaped target labels and reduced batch size\n",
    "model.fit(X_train, Y_train_reshaped, epochs=10, batch_size=batch_size, validation_data=(X_test, Y_test_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63025b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training history\n",
    "history = model.fit(X_train, Y_train_reshaped, epochs=10, batch_size=batch_size, validation_data=(X_test, Y_test_reshaped))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9ea39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9d54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30166bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0869589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f4a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af193cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44626f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76315ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0f4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33ce11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf6f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2745e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a383c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598740b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c3b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d46f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55caa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b918ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
